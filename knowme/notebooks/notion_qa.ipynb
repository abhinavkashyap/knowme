{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from knowme.ingest import NotionIngestor\n",
    "from knowme.embedder import ChromaEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingestor = NotionIngestor(\n",
    "    folder_path=\"/Users/abhinavkashyap/abhi/projects/knowme/abhinav_notion\"\n",
    ")\n",
    "texts, metadatas = ingestor.ingest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = text_splitter.create_documents(texts=texts, metadatas=metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Let's explore this paper to better understand the claimed advantages and improvements over GPT-3.\\n\\n## Mixture of Experts\\n\\n![Screenshot 2023-11-27 at 5.38.08 PM.png](GLaM%20Efficient%20Scaling%20of%20Language%20Models%20with%20Mix%20daa1c17d134249129c43a311d3ff31c5/Screenshot_2023-11-27_at_5.38.08_PM.png)\\n\\nThis is a transformer block. The major computational bottleneck in Transformers is the FFN or the Feedforward Neural Network Component. Instead of a single FFN layer, can we replace it with multiple FFN modules? We can. These individual FFN modules are called experts. Doing this can have multiple advantages:\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(documents))\n",
    "documents[10].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "store = ChromaEmbedder(text_splitter, embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromastore = store.store_embeddings(texts, metadatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = chromastore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "retrieved_docs = retriever.invoke(\"What does Abhinav work as?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='[https://notaku.so/iframes/clickable-image/eyJpbWFnZVVybCI6Imh0dHBzOi8vZW5jcnlwdGVkLXRibjAuZ3N0YXRpYy5jb20vaW1hZ2VzP3E9dGJuOkFOZDlHY1RMV0FlbWMzMFZRZkluMEFuU3AybDE1dUR2WXptYUZfdU1YZyZ1c3FwPUNBVSIsImxpbmtIcmVmIjoiaHR0cHM6Ly90d2l0dGVyLmNvbS9hYmthc2h5YXA5MiJ9](https://notaku.so/iframes/clickable-image/eyJpbWFnZVVybCI6Imh0dHBzOi8vZW5jcnlwdGVkLXRibjAuZ3N0YXRpYy5jb20vaW1hZ2VzP3E9dGJuOkFOZDlHY1RMV0FlbWMzMFZRZkluMEFuU3AybDE1dUR2WXptYUZfdU1YZyZ1c3FwPUNBVSIsImxpbmtIcmVmIjoiaHR0cHM6Ly90d2l0dGVyLmNvbS9hYmthc2h5YXA5MiJ9)\\n\\nHey Iâ€™m Abhinav. I am a AI Scientist at ASUS-AICS. I work on Natural Language Processing and I am  interested in processing clinical notes.', metadata={'filename': '/Users/abhinavkashyap/abhi/projects/knowme/abhinav_notion/Abhinav Ramesh Kashyap 2a5b5c4c70f240359dc297eaa025b430.md', 'start_index': 0})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some of the information is there in the first retrieved document\n",
    "# I might have to do some cleaning on the ingestion side\n",
    "retrieved_docs[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knowme-Vm6gcGsG-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
